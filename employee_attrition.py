# -*- coding: utf-8 -*-
"""Employee Attrition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19qFoQi7y-0faSNwWt7QpHnEZZxP0PrNk
"""

import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.offline as py
py.init_notebook_mode(connected=True)
import plotly.graph_objs as go
import plotly.tools as tls
import plotly.figure_factory as ff
import pickle
from scipy import stats


from sklearn.preprocessing import LabelEncoder

# to split data into test, train  and validation
from sklearn.model_selection import train_test_split
import sklearn.metrics

# Data Balancing
from imblearn.over_sampling import RandomOverSampler
from imblearn.over_sampling import SMOTE, ADASYN
from imblearn.under_sampling import RandomUnderSampler
from collections import Counter

# Data Modelling
from xgboost import XGBClassifier
from sklearn.utils import shuffle

# Data Evaluation
from sklearn.metrics import classification_report
from sklearn.metrics import roc_curve, roc_auc_score
from sklearn.metrics import RocCurveDisplay
from sklearn.metrics import accuracy_score, confusion_matrix, f1_score,classification_report
from sklearn.metrics import mean_squared_error,mean_absolute_error

# installing and importing data prep for visualisations and analysis
!pip install -U dataprep
from dataprep.eda import plot
from dataprep.datasets import load_dataset

from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler

"""# Data Overview"""

# Read in csv file
data = pd.read_csv("WA_Fn-UseC_-HR-Employee-Attrition.csv")
data.head()

# Check for duplications
data.duplicated()

# check for null values
data.isnull()

"""No duplicates are observed in the dataset."""

# Commented out IPython magic to ensure Python compatibility.
!pip install autoviz
from autoviz.AutoViz_Class import AutoViz_Class
AV = AutoViz_Class()

# %matplotlib inline 
# AutoViz no displays plots automatically. You must perform %matplotlib inline just before you run AutoViz on your data.

# Generate visualizations
AV.AutoViz("WA_Fn-UseC_-HR-Employee-Attrition.csv")

filename = ""
sep = ","
df_age_income = data[['Age', 'MonthlyIncome']]
AV = AutoViz_Class()

AV.AutoViz( filename, dfte=df_age_income, depVar='MonthlyIncome', verbose=1,lowess=True)

import matplotlib.pyplot as plt

# Create a filtered DataFrame with only attrition cases
attrition_df = data[data['Attrition'] == 'Yes']

# Plot a histogram of Age for attrition cases
plt.hist(attrition_df['Age'], bins=20, alpha=0.3, color='blue')

# Create a filtered DataFrame with non-attrition cases
non_attrition_df = data[data['Attrition'] == 'No']

# Plot a histogram of Age for non-attrition cases on the same plot
plt.hist(non_attrition_df['Age'], bins=20, alpha=0.5, color='lightblue')

# Add labels and legend to the plot
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.title('Age vs Attrition')
plt.legend(['Attrition', 'No Attrition'])

# Show the plot
plt.show()

# select the desired features
selected_features = ['Age', 'MonthlyIncome', 'YearsInCurrentRole', 'JobRole', 'JobSatisfaction', 'JobLevel', 'Attrition',
                     'PercentSalaryHike','PerformanceRating','YearsAtCompany','YearsSinceLastPromotion','TotalWorkingYears']

# create a new dataframe with selected features
selected_data = data[selected_features]

# calculate correlation matrix
corr_matrix = selected_data.corr()

# plot the heatmap
fig, ax = plt.subplots(figsize=(8, 5))
ax.xaxis.tick_top()
sns.heatmap(corr_matrix, annot=True)

"""The heatmap above displays correlation between features that could potantially have an effect on attrition rates. Values over 0.60 have been considered for further analysis as they represent a strong correlation between variables. Regions of high correlation are observed in JobLevel vs MonthlyIncome followed by YearsAtCompany vs YearsInCurrentRole and MonthlyIncome vs TotalWorkingYears


"""

df_age_income.head()

"""# Additional Dataset"""

data_add = pd.read_csv("employee_attrition_train.csv")
data_add.head()

data_add = data_add.dropna()

data_add.head()

data_add.info()

# Convert Age from float to int
data_add['Age'] = data_add['Age'].astype(int)

# Display the dataframe
print(data_add)

# Select the columns you want to keep
columns_to_keep = ['Age','Attrition', 'Education', 'EnvironmentSatisfaction', 'JobInvolvement','JobLevel',
                   'JobSatisfaction','MonthlyIncome','PerformanceRating','RelationshipSatisfaction',
                   'StockOptionLevel','TotalWorkingYears','TrainingTimesLastYear','WorkLifeBalance',
                   'YearsAtCompany','YearsInCurrentRole','YearsWithCurrManager']

# Create a new dataframe with only the selected columns
data_add_new = data_add.loc[:, columns_to_keep]

data_add_new.head()

train_x = pd.read_pickle( "./train_x_smote_dropped_v2.pkl")

train_x.dtypes

merged_df = pd.concat([train_x, data_add_new])

merged_df.info()

merged_df.head()

df_no_duplicates = merged_df.drop_duplicates()
df_no_duplicates.info()

pd.to_pickle(merged_df, "./merged_train_x.pkl")

train_y = pd.read_pickle( "./train_y_encode_smote_v2.pkl")

train_y.head()

y_column = ['Attrition']
data_add_y = data_add.loc[:,'Attrition']
data_add_y.head()

labelencoder = LabelEncoder()

# Apply LabelEncoder to each categorical column
for col in data_add_y:
    labelencoder = LabelEncoder()
    data_add_y = labelencoder.fit_transform(data_add_y)

data_add_y

data_add_y = pd.DataFrame(data_add_y)

data_add_y.head()

merged_df_y = pd.concat([train_y, data_add_y])

merged_df_y.info()

pd.to_pickle(merged_df_y, "./merged_train_y.pkl")

"""# Data Analysis

## Summary

The dataset consists of 1470 observations and 35 variables. The dataset is made up of numerical and categorical values. Categorical values will be converted into their numerical form using LabelEncoding. There are no null data types.
"""

data.shape

data.info()

data.describe()

# Observe distribution of Attrition and Retention employees

# Reassign target
# data.Attrition.replace(to_replace = dict(Yes = 1, No = 0), inplace = True)
my_labels =["No Attriton","Attrition"]
plt.pie(data['Attrition'].value_counts(), labels=my_labels,autopct='%1.1f%%')
plt.title('Distribution of Attrition')

"""It can be seen that the dataset is highly baised as towards retention cases. Due to that predictions will be skewed towards low attrition cases. Dataset needs to be balanced with the help of imblearn"""

# Split data into numerical and categorical values
numeric_cols = data.select_dtypes(include=['int64', 'float64']).columns
categorical_cols = data.select_dtypes(include=['object']).columns

# Use above columns to create new dataframes from original

df_numerical = data[(numeric_cols)]                      
df_numerical.info()

df_categorical = data[(categorical_cols)]                      
df_categorical.info()

"""#### Visualising Numerical Values"""

# Set up the plot
fig, axes = plt.subplots(13, 2, figsize=(10, 30))
sns.set_style('whitegrid')

# Plot each column using a for loop
for ax, col in zip(axes.flatten(), df_numerical.columns):
    sns.histplot(df_numerical[col], ax=ax, kde=True)
    ax.set(title=f'Distribution plot of {col}')

# Show the plot
plt.tight_layout()
plt.show()

# Visualising EmployeeCount, EmployeeNumber and StandardHours
# Set up the plot
sns.set_style('whitegrid')
fig, axes = plt.subplots(1, 3, figsize=(20, 5))

# Declare columns to visualise
vis = ['EmployeeCount','EmployeeNumber','StandardHours']
# Plot each column using a for loop
for ax, col in zip(axes.flatten(), vis):
    sns.histplot(df_numerical[col], ax=ax, kde=True)
    ax.set(title=f'Distribution plot of {col}')

# Show the plot
plt.tight_layout()
plt.show()

"""EmployeeCount is a single value feature that has no effect on the Attrition and therefore is dopped.
EmployeeNumber is a unique identifier with no distict features and therefore is dropped.
StandardHours is also a single value feature with no effect on attrition and therefore is dropped
"""

# Visualising YearsInCurrRole and YearsWithCurrManager

# Declare columns to visualise
vis = ['YearsInCurrentRole','YearsWithCurrManager']

# Set up the plot
sns.set_style('whitegrid')
fig, axes = plt.subplots(1, 2, figsize=(20, 5))
# Plot each column using a for loop
for ax, col in zip(axes.flatten(), vis):
    sns.histplot(df_numerical[col], ax=ax, kde=True)
    ax.set(title=f'Distribution plot of {col}')

# Show the plot
plt.tight_layout()
plt.show()

"""Both YearsInCurrentRole and YearsWithCurrManager shows a bimodal distribution. This could indicate that there are two groups of employees with different levels of experience. First group represents newer employees who have recently joined the company and are still settling in with their roles as the peak shows between 2-2.5 years. Second group may represent employees who are more established in their roles as shown with peaks between 7-7.5. This trend suggests that employees who are comfortable their role and current manager and those who are gaining experience are less likely to leave the company.

#### Visualising Categorical Values
"""

# Label encode categorical values

# Create an instance of LabelEncoder 
labelencoder = LabelEncoder()

# Apply LabelEncoder to each categorical column
for col in df_categorical:
    labelencoder = LabelEncoder()
    df_categorical[col] = labelencoder.fit_transform(df_categorical[col])

df_categorical

# Set up the plot
fig, axes = plt.subplots(5, 2, figsize=(10, 15))
sns.set_style('whitegrid')

# Plot each column using a for loop
for ax, col in zip(axes.flatten(), df_categorical.columns):
    sns.histplot(df_categorical[col], ax=ax, kde=True)
    ax.set(title=f'Distribution plot of {col}')

# Show the plot
plt.tight_layout()
plt.show()

"""Over18 are single value features and are removed

## Further Analysis of different features

#### Analysis of Employee Information
"""

fig, axes = plt.subplots(1, 3, figsize=(25, 5))

sns.boxplot(ax=axes[0], x='Gender', y='Age', hue='Attrition', data=data, color='#ADD8E6')
sns.boxplot(ax=axes[1], x='Education', y='Age', hue='Attrition', data=data, color='#ADD8E6')
sns.boxplot(ax=axes[2], x='MaritalStatus', y='Age', hue='Attrition', data=data, color='#ADD8E6')

axes[0].set_title('Attrition in Gender vs Age')
axes[1].set_title('Attrition in Education vs Age')
axes[2].set_title('Attrition in MaritalStatus vs Age')


plt.show()

"""Boxplot for Attrition in Gender vs Age shows that Male employees between the ages 35-40 are more likely to leave the company than thoe below 30. Female employees are more likely to leave in their early 30s and ages between 35 and 45 show a much higher retention rate than males. Education vs Age shows that employees with Education level 2 (College level) are more likely to be laid off or quit between the ages 30-45. Attritions rates decrease as the level of education increases. This indicates that employees with higher education are more likely to remain with the company as they are more valuable and have shorter age ranges. Employees below 30 are most likely to leave irrespective of their gender or marital status

#### Analysis of Employee Company Information
"""

# Attrition in each job role
fig, axes = plt.subplots( figsize=(25, 5))
# sns.histplot(ax=axes[0],data=data, x='Department', hue='Attrition', multiple='dodge', color='#ADD8E6')
sns.histplot(data=data, x='JobRole', hue='Attrition', multiple='dodge', color='#ADD8E6')

# axes[0].set_title('Attrition in each department')
# axes[1].set_title('Attrition in each job role')

plt.show()

"""From the histogram plot, key observations are the high rates are within Sales and Research & Development departments among which Sales Executives, Research Scientists and Laboratory Technicians display high rates. There could be multiple factors that effect attrition rates in these roles and require further analysis."""

# Analysing Attrition in JobRole vs MonthIncome
fig, axes = plt.subplots( figsize=(20, 7))
box_plot= sns.boxplot( x='JobRole', y='MonthlyIncome', hue='Attrition', data=data, color='#ADD8E6',showmeans=True)
plt.show()

# add labels for median value
medians = data.groupby(['JobRole'])['MonthlyIncome'].median()
vertical_offset = data['MonthlyIncome'].median() * 0.05 # offset from median for display
for xtick in axes.get_xticks():
    axes.text(xtick, medians[xtick] + vertical_offset, medians[xtick], 
            horizontalalignment='center', size='medium', color='black', weight='semibold')

attrition = data[(data['Attrition'] == 'Yes')]
no_attrition = data[(data['Attrition'] == 'No')]

print(attrition.groupby(['JobRole'])['MonthlyIncome'].describe())

print(no_attrition.groupby(['JobRole'])['MonthlyIncome'].describe())

"""Comparing Sale Executive and Manufacturing Director, both roles have a similar median of monthly income for both attrited and retained employees. However, the mean income of attrited Sales Executives is higher than that of retained Manufacturing Directors indicating that income isn't a factor as to why Sales Executives are leaving the company. On the other hand, Research Scientists that remained with the company have a higher mean income than those that have left suggesting that income may be a leading factor for that job role.
Both Research Scientists and Laboratory Technicians receive the lowest monthly incomes alongside Sales Representatives. These roles have also shown alot of outlier values compared to other roles. These are key contributors to attrition rates however there may be more factors affecting Research Scientists and Laboratory Technicians. 


"""

# Analysing Attrition in Department vs MonthlyIncome
fig, axes = plt.subplots( figsize=(15, 5))
sns.boxplot( x='Department', y='MonthlyIncome', hue='Attrition', data=data, color='#ADD8E6')
plt.show()

"""It can be concluded that Sales and Research & Development Departments have a considerable amount of outliers."""

fig, axes = plt.subplots(1, 2, figsize=(25, 5))

attrition.plot(ax=axes[0],
    kind='scatter',
    x='JobRole',
    y='MonthlyIncome',
    title='JobRole vs MonthlyIncome of Attrited Employees',
)

no_attrition.plot(ax=axes[1],
    kind='scatter',
    x='JobRole',
    y='MonthlyIncome',
    title='JobRole vs MonthlyIncome of Retained Employees'
)
axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=90)
axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=90)
plt.show()

# Analysing Attrition in JobRole vs YearsSinceLastPromotion
fig, axes = plt.subplots( figsize=(25, 7))
sns.boxplot( x='JobRole', y='YearsSinceLastPromotion', hue='Attrition', data=data, color='#ADD8E6')
plt.show()

# Analysing Attrition in JobRole vs YearsAtCompany
fig, axes = plt.subplots( figsize=(25, 7))
sns.boxplot( x='JobRole', y='YearsAtCompany', hue='Attrition', data=data, color='#ADD8E6')
plt.show()

"""

*   Research directors show high attrition rates after having worked for a company for more than 20 years. This suggests that the employees who left the company may have had lower salaries, lower job satisfaction that contributed to their decision to leave


"""

# Analysing Attrition in JobRole vs PercentSalaryHike
fig, axes = plt.subplots( figsize=(20, 7))
sns.boxplot( x='JobRole', y='PercentSalaryHike', hue='Attrition', data=data, color='#ADD8E6')
plt.show()

# Analysing work life balance of different job roles
fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(20, 6))

# create a bar chart for Attrition Yes
ax1 = attrition.groupby(['JobRole', 'WorkLifeBalance'])['Attrition'].count().unstack('WorkLifeBalance').plot(kind='bar', ax=ax1)
ax1.set_xlabel('Job Role')
ax1.set_ylabel('Count')
ax1.set_title('WorkLifeBalance vs JobRole for Attrited employees')

# create a bar chart for Attrition No
ax2 = no_attrition.groupby(['JobRole', 'WorkLifeBalance'])['Attrition'].count().unstack('WorkLifeBalance').plot(kind='bar', ax=ax2)
ax2.set_xlabel('Job Role')
ax2.set_ylabel('Count')
ax2.set_title('WorkLifeBalance vs JobRole for Retained employees')

# display the plots
plt.tight_layout()
plt.show()

"""From the graphs it can be noted that Laboratory Technicians that have worse WorkLifeBalance are more likely to leave when compared to other job roles. Not only are do they receieve lower monthly income but also have a bad work life balance which are key determinants as to why they are leaving."""

plt.scatter(data['YearsAtCompany'], data['YearsSinceLastPromotion'])
plt.xlabel('YearsAtCompany')
plt.ylabel('YearsSinceLastPromotion')
plt.title('YearsAtCompany vs YearsSinceLastPromotion')
plt.show()

"""*   There is a positive correlation between years worked at company and promotion. 
*   There is a strong indication that high attrition rates amongst Research Scientists and Laboratory Technicians could be attributed to lack of experience and promotion as a result of less years worked at the company. Although attrited employees receive similar monthly income as retained employees, their bad work life balance is a leading cause for them to quit.

#### Analysis of Heatmap correlations
"""

# assuming you have a dataframe named 'df' containing the employee data
joblevel3_df = data[data['JobLevel'] == 3] # filter for employees with JobLevel 3
jobrole_counts = joblevel3_df['JobRole'].value_counts() # count employees in each job role

# plot horizontal bar chart
plt.barh(jobrole_counts.index, jobrole_counts.values)
plt.title('Employees with JobLevel 3 by Job Role')
plt.xlabel('Count')
plt.ylabel('Job Role')
plt.show()

# create figure and axis objects with subplots()
fig, axs = plt.subplots(1, 2, figsize=(30, 7))

# plot boxplot on first axis
sns.boxplot(x='JobLevel', y='MonthlyIncome', hue='Attrition', data=data, color='#ADD8E6', ax=axs[0])
axs[0].set_title('Attrition in JobLevel vs MonthlyIncome')

# plot horizontal bar chart on second axis
joblevel3_df = data[data['JobLevel'] == 3] # filter for employees with JobLevel 3
jobrole_counts = joblevel3_df['JobRole'].value_counts() # count employees in each job role
axs[1].barh(jobrole_counts.index, jobrole_counts.values)
axs[1].set_title('Employees with JobLevel 3 by Job Role')

plt.show()

"""By plotting Monthly Income vs Job Level using a box plot, it was observed that employees with a Job Level of 3 have the highest attrition rate. The plot shows that employees with a higher job level generally have a higher monthly income, which may explain the higher attrition rate among Job Level 3 employees, who may feel stuck and undervalued in their current position. To investigate which job roles have the most employees with a Job Level of 3, data is filtered to include only Job Level 3 employees with a count of the number of employees in each job role. This revealed that Sales Representatives have the highest number of employees with a Job Level of 3, indicating that this group may be particularly susceptible to attrition.


"""

# Analysing Attrition in YearsAtCompany vs YearsInCurrentRole
fig, axes = plt.subplots( figsize=(15, 5))
sns.boxplot( x='YearsInCurrentRole', y='YearsAtCompany', hue='Attrition', data=data, color='#ADD8E6')
plt.show()

# Analysing Attrition in TotalWorkingYears vs MonthlyIncome
fig, axes = plt.subplots( figsize=(15, 5))
sns.boxplot( x='TotalWorkingYears', y='MonthlyIncome', hue='Attrition', data=data, color='#ADD8E6')
plt.show()

# Analysing Attrition in TotalWorkingYears vs YearsSinceLastPromotion
fig, axes = plt.subplots( figsize=(15, 5))
sns.boxplot( x='JobRole', y='YearsSinceLastPromotion', hue='Attrition', data=data, color='#ADD8E6')
plt.show()

"""## Outlier Analysis

### Z-Score
"""

# Calculate the mean and standard deviation
mean = np.mean(data)
std_dev = np.std(data)

# Calculate the z-scores for each data point
z_scores = (data - mean) / std_dev

# Choose a threshold z-score value
threshold = 3

# Identify the outliers
outliers = data[np.abs(z_scores) > threshold]

# print scores and outliers
print("Z-scores:", z_scores)
print("Outliers:", outliers)

"""### Using Upper and Lower Quartile Ranges"""

col_mean = data['MonthlyIncome'].mean()
col_std = data['MonthlyIncome'].std()
col_var = data['MonthlyIncome'].var()

print(col_mean)
print(col_std)
print(col_var)

data['MonthlyIncome'].describe()

lower_limit = col_mean - (2 * col_std)
upper_limit = col_mean + (2 * col_std)

outliers2= data[(data['MonthlyIncome'] < lower_limit) | (data['MonthlyIncome'] > upper_limit)]

print("Outliers: ", outliers2['MonthlyIncome'])

"""# Split into Testing and Training"""

# LabelEncode Categorical Values of dataset
# Create an instance of LabelEncoder 
labelencoder = LabelEncoder()

# Apply LabelEncoder to each categorical column
for col in categorical_cols:
    # labelencoder = LabelEncoder()
    labelencoder.fit(data[col])
    data[col] = labelencoder.transform(data[col])

data.head()

training_data, testing_data = train_test_split(data, test_size=0.2, random_state=25)

training_data['Attrition'].value_counts()

testing_data['Attrition'].value_counts()

len(training_data)

training_data.head()

len(testing_data)

testing_data.head()

pd.to_pickle(training_data, "./training.pkl")
pd.to_pickle(testing_data, "./testing.pkl")

"""# Data Balancing with Imblearn"""

training_data = pd.read_pickle( "./training_v2.pkl")

testing_data = pd.read_pickle("./testing_v2.pkl")

# Separate Attrition Column into train_y
cols = list(training_data.columns)
cols.remove('Attrition')

train_x = training_data.loc[:,cols]
train_y = training_data.loc[:,'Attrition']

# print(train_x)

# Separate Attrition Column into test_x and test_y
cols = list(testing_data.columns)
cols.remove('Attrition')

test_x = testing_data.loc[:,cols]
test_y = testing_data.loc[:,'Attrition']

# print(train_x)

# pd.to_pickle(train_x, "./train_x_imb.pkl")
# pd.to_pickle(train_y, "./train_y_imb.pkl")

# Over-sampling with SMOTE
X_resampled, y_resampled = SMOTE().fit_resample(train_x, train_y)
print(sorted(Counter(y_resampled).items()))

# Display Distibution of Attrition after over-sampling with SMOTE
my_labels =["No Attriton","Attrition"]
plt.pie(y_resampled.value_counts(), labels=my_labels,autopct='%1.1f%%')
plt.title('Distribution of Attrition after SMOTE resampling')

"""1.   SMOTE will not make any distinction between easy and hard samples to be classified using the nearest neighbors rule.
2.   SMOTE generates synthetic samples for the minority class by randomly selecting a minority sample and computing the difference between that sample and its nearest neighbors. The synthetic sample is then generated by adding this difference to the original sample.



"""

# Save resampled data
pd.to_pickle(X_resampled, "./train_x_encode_smote.pkl")
pd.to_pickle(y_resampled, "./train_y_encode_smote.pkl")

# Over-sampling with ADASYN 
X_resampled_1, y_resampled_1 = ADASYN().fit_resample(train_x, train_y)
print(sorted(Counter(y_resampled_1).items()))

# Display Distibution of Attrition after over-sampling with ADASYN
my_labels =["No Attriton","Attrition"]
plt.pie(y_resampled_1.value_counts(), labels=my_labels,autopct='%1.1f%%')
plt.title('Distribution of Attrition after ADASYN resampling')

"""
*   ADASYN focuses on generating samples next to the original samples which are wrongly classified using a k-Nearest Neighbors classifier.

*   ADASYN generates synthetic samples based on the density distribution of the minority class.
ADASYN generates more synthetic samples in regions where the minority class is under-represented compared to SMOTE. ADASYN can therefore be more effective in addressing the imbalanced class distribution, particularly in datasets where the minority class is concentrated in specific regions of the feature space







"""

# Save resampled data
pd.to_pickle(X_resampled_1, "./train_x_encode_adasyn.pkl")
pd.to_pickle(y_resampled_1, "./train_y_encode_adasyn.pkl")

"""# Feature Engineering"""

train_x_smote = pd.read_pickle( "./train_x_encode_smote_v2.pkl")
train_y_smote = pd.read_pickle("./train_y_encode_smote_v2.pkl")

train_x_adasyn = pd.read_pickle( "./train_x_encode_adasyn_v2.pkl")
train_y_adasyn = pd.read_pickle("./train_y_encode_adasyn_v2.pkl")

# Drop irrelevant features
train_x_smote = train_x_smote.drop(columns=['EmployeeCount', 'EmployeeNumber','StandardHours', 'Over18'])
train_x_adasyn = train_x_adasyn.drop(columns=['EmployeeCount', 'EmployeeNumber','StandardHours', 'Over18'])

"""## Feature Selection for Categorical Features"""

# Import libraries for categorical feature selection
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import mutual_info_classif,chi2

# Feature selection using Chi-squared Score and SMOTE
selector = SelectKBest(score_func = chi2 ,k = 'all')
fit = selector.fit(train_x_smote,train_y_smote)

scores = pd.DataFrame(data = fit.scores_,index = list(train_x_smote.columns),columns = ['Chi-squared Score']) 

plt.subplots(figsize = (20,15))
sns.heatmap(scores.sort_values(ascending = False,by = 'Chi-squared Score'),annot = True,linewidths = 0.4,linecolor = 'black',fmt = '.2f');
plt.title('Selection of Categorical Features using SMOTE Balancing');

# Feature selection using Chi-squared Score and ADASYN
selector = SelectKBest(score_func = chi2 ,k = 'all')
fit = selector.fit(train_x_adasyn,train_y_adasyn)

scores = pd.DataFrame(data = fit.scores_,index = list(train_x_adasyn.columns),columns = ['Chi-squared Score']) 

plt.subplots(figsize = (20,15))
sns.heatmap(scores.sort_values(ascending = False,by = 'Chi-squared Score'),annot = True,linewidths = 0.4,linecolor = 'black',fmt = '.2f');
plt.title('Selection of Categorical Features using ADASYN Balancing');

"""Chi-squared test has been done on training set balanced with SMOTE and ADASYN. Both show similar results with a few categories scoring differently. Features that display scores below 40 are dropped from the dataset as they show little correlation with Attrition. These include: MaritalStatus, JobRole, Department, Business Travel, EducationField, OverTime and Gender

## Feature Selection for Numerical Features
"""

from sklearn.feature_selection import f_classif
# Declare selector with ANOVA
selector = SelectKBest(score_func = f_classif ,k = 'all')

# Get all numerical features from train_x
numeric_cols = train_x_smote.select_dtypes(include=['int64', 'float64']).columns
num_features = train_x_smote.loc[:,numeric_cols]
fit = selector.fit(num_features,train_y_smote)

scores = pd.DataFrame(data = fit.scores_,index = list(num_features.columns),columns = ['Chi-squared Score']) 

plt.subplots(figsize = (20,15))
sns.heatmap(scores.sort_values(ascending = False,by = 'Chi-squared Score'),annot = True,linewidths = 0.4,linecolor = 'black',fmt = '.2f');
plt.title('Selection of Numerical Features using SMOTE Balancing');

"""ANOVA test done on numerical categories. Categories scoring below 50 are dropped from the dataset as they show little correlation with Attrition. This includes: NumCompaniesWorked, MonthlyRate, HourlyRate, PercentageSalaryHike, DistanceFromHome, DailyRate, YearsSinceLastPromotion

## Dropping low correlated features

1.  Categorical Features :  'MaritalStatus', 'JobRole', 'Department', 'Business Travel', 'EducationField', 'OverTime', 'Gender'
2.  Numerical Features: 'NumCompaniesWorked', 'MonthlyRate', 'HourlyRate', 'PercentageSalaryHike', 'DistanceFromHome', 'DailyRate', 'YearsSinceLastPromotion'

PerformanceRating shows contrasting scores. It outputs very low scores when calculated with Chi-squared but shows very high score when calculated with ANOVA.
As it is a numarical category I will be taking into account scores from ANOVA test and as a result will not be dropping it.
"""

train_x_smote = train_x_smote.drop(columns=['MaritalStatus', 'JobRole', 'Department', 'BusinessTravel', 'EducationField', 'OverTime', 'Gender',
                                            'NumCompaniesWorked', 'MonthlyRate', 'HourlyRate', 'PercentSalaryHike', 'DistanceFromHome', 'DailyRate', 'YearsSinceLastPromotion'])

train_x_adasyn = train_x_adasyn.drop(columns=['MaritalStatus', 'JobRole', 'Department', 'BusinessTravel', 'EducationField', 'OverTime', 'Gender',
                                            'NumCompaniesWorked', 'MonthlyRate', 'HourlyRate', 'PercentSalaryHike', 'DistanceFromHome', 'DailyRate', 'YearsSinceLastPromotion'])

train_x_adasyn.dtypes

train_x_smote
pd.to_pickle(train_x_smote, "./train_x_smote_dropped.pkl")

train_x_adasyn
pd.to_pickle(train_x_adasyn, "./train_x_adasyn_dropped.pkl")

"""## Drop features from test set too """

# Drop irrelevant features
test_x = test_x.drop(columns=['EmployeeCount', 'EmployeeNumber','StandardHours', 'Over18'])

test_x = test_x.drop(columns=['MaritalStatus', 'JobRole', 'Department', 'BusinessTravel', 'EducationField', 'OverTime', 'Gender',
                                            'NumCompaniesWorked', 'MonthlyRate', 'HourlyRate', 'PercentSalaryHike', 'DistanceFromHome', 'DailyRate', 'YearsSinceLastPromotion'])

test_x.dtypes

pd.to_pickle(test_x, "./test_x_dropped.pkl")
pd.to_pickle(test_y, "./test_y_dropped.pkl")

"""# Data Scaling"""

from sklearn.preprocessing import MinMaxScaler,StandardScaler
mms = MinMaxScaler()
scaler = StandardScaler()

train_x_smote = pd.read_pickle( "./train_x_smote_dropped_v2.pkl")
train_x_adasyn = pd.read_pickle( "./train_x_adasyn_dropped_v2.pkl")

test_x = pd.read_pickle("./test_x_dropped.pkl")

"""## Normalisation

Normalising columns that does not show Gaussian distribution
"""

# declare columns that need normalising
norm_columns = ['MonthlyIncome', 'YearsWithCurrManager','YearsInCurrentRole','YearsAtCompany','TotalWorkingYears']

# Apply LabelEncoder to each categorical column
for col in norm_columns:
    # labelencoder = LabelEncoder()
     scaler.fit(train_x_smote[[col]])
     train_x_smote[col] = scaler.transform(train_x_smote[[col]])

train_x_smote.head()

train_x_smote.info()

plot(train_x_smote, 'MonthlyIncome')

"""## Standardisation

# Modelling
"""

train_x_smote = pd.read_pickle( "./train_x_smote_dropped_v2.pkl")
train_y_smote = pd.read_pickle( "./train_y_encode_smote_v2.pkl")

train_x_adasyn = pd.read_pickle( "./train_x_adasyn_dropped_v2.pkl")
train_y_adasyn = pd.read_pickle( "./train_y_encode_adasyn_v2.pkl")

test_x = pd.read_pickle( "./test_x_dropped.pkl")
test_y = pd.read_pickle( "./test_y_dropped.pkl")

merged_x = pd.read_pickle( "./merged_train_x.pkl")
merged_y = pd.read_pickle( "./merged_train_y.pkl")
merged_x.head()

merged_y.head()

"""## Functions for model training and evaluation"""

def train_and_plot(train_x, train_y, test_x, test_y, model_name, learning_rate, max_depth, min_child_weight):
  classifier_xgb = XGBClassifier(learning_rate= learning_rate,max_depth = max_depth, min_child_weight= min_child_weight, n_estimators = 1000)

  classifier_xgb.fit(train_x,train_y)

  # Save Model
  mod_file = model_name
  pickle.dump(classifier_xgb, open(mod_file, 'wb'))

  y_pred = classifier_xgb.predict(test_x)
  y_proba = classifier_xgb.predict_proba(test_x)[:,1]

  print(classification_report(test_y,y_pred))


  fpr, tpr, _ = roc_curve(test_y, y_proba)
  roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)
  auc = roc_auc_score(test_y, y_proba)

  # Create Receiver Operating Characteristic curve
  plt.figure(figsize = (5,5))
  plt.plot(fpr,tpr,label="AUC= "+str(auc))
  plt.ylabel('True Positive Rate (Sensitivity)')
  plt.xlabel('False Positive Rate (Specificity)')
  plt.legend(loc=4)
  plt.show()

  accuracy = accuracy_score(test_y,y_pred)
  print("Accuracy :",accuracy)

  f1Score= f1_score(test_y,y_pred,average=None)
  print("F1 Score :",f1Score)

  conf_mat = confusion_matrix(test_y,y_pred)
  print("Confusion Matrix :",conf_mat)


  group_names = ['True Neg','False Pos','False Neg','True Pos']
  group_counts = ['{0:0.0f}'.format(value) for value in
                  conf_mat.flatten()]
  group_percentages = ['{0:.2%}'.format(value) for value in
                      conf_mat.flatten()/np.sum(conf_mat)]
  labels = [f'{v1}\n{v2}\n{v3}' for v1, v2, v3 in
            zip(group_names,group_counts,group_percentages)]
  labels = np.asarray(labels).reshape(2,2)
  sns.heatmap(conf_mat, annot=labels, fmt='')

  print("Mean-squared error: ",mean_squared_error(test_y, y_pred))
  print("Root mean-squared error: ",mean_squared_error(test_y, y_pred, squared=False))
  print("Mean absolute error: ",mean_absolute_error(test_y, y_pred))

"""## Logistic Regression"""

# Train model
log_reg = LogisticRegression()
log_reg.fit(train_x_adasyn,train_y_adasyn)

# Save Model
mod_file = 'log_reg_adasyn.model'
pickle.dump(log_reg, open(mod_file, 'wb'))

log_reg.score(train_x_adasyn,train_y_adasyn)

# import model
log_reg = pickle.load(open('log_reg_adasyn.model', 'rb'))

# make a prediction
y_pred = log_reg.predict(test_x)

y_proba = log_reg.predict_proba(test_x)[:,1]

from sklearn.metrics import classification_report

print(classification_report(test_y,y_pred))

from sklearn.metrics import accuracy_score, confusion_matrix, f1_score,classification_report

accuracy = accuracy_score(test_y,y_pred)
print("Log reg Acurracy :",accuracy)

f1Score= f1_score(test_y,y_pred,average=None)
print("F1 Score :",f1Score)

conf_mat = confusion_matrix(test_y,y_pred)
print("Confusion Matrix :",conf_mat)

from sklearn.metrics import roc_curve, roc_auc_score
from sklearn.metrics import RocCurveDisplay

fpr, tpr, _ = roc_curve(test_y, y_proba)
roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)
auc = roc_auc_score(test_y, y_proba)

# Create Receiver Operating Characteristic curve
plt.figure(figsize = (10,10))
plt.plot(fpr,tpr,label="AUC= "+str(auc))
plt.ylabel('True Positive Rate (Sensitivity)')
plt.xlabel('False Positive Rate (Specificity)')
plt.legend(loc=4)
plt.show()

"""The steps in the curve occur when the predicted probabilities of the minority class change, leading to changes in the false positive rate (FPR) and true positive rate (TPR). The step-like shape indicates that the classifier is able to achieve high levels of TPR with only a small increase in FPR. 

In the above curve, to achieve a very low false positive rate, 0.8 threshold is good option as it can be seen that there is a steep increase or true postives indicating that the model is learning approriately. However, after 0.5 threshold, severly diminishing returns are observed as there aren't many improvements to TPR due to an increasing FPR.

This is an indication that there aren't many samples in the data therefore the models is unable to generalise and is overfitting to a small dataset. To solve this issue, I have decided to create an even bigger dataset by merging the original with an external one.






"""

group_names = ['True Neg','False Pos','False Neg','True Pos']
group_counts = ['{0:0.0f}'.format(value) for value in
                conf_mat.flatten()]
group_percentages = ['{0:.2%}'.format(value) for value in
                    conf_mat.flatten()/np.sum(conf_mat)]
labels = [f'{v1}\n{v2}\n{v3}' for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(conf_mat, annot=labels, fmt='')

from sklearn.metrics import mean_squared_error,mean_absolute_error

mean_squared_error(test_y, y_pred)

mean_squared_error(test_y, y_pred, squared=False)

mean_absolute_error(test_y, y_pred)

"""## XGBoost

### Train with Original Data
"""

from xgboost import XGBClassifier
classifier_xgb = XGBClassifier(learning_rate= 0.01,max_depth = 3,n_estimators = 1000)

classifier_xgb.fit(train_x_smote,train_y_smote)

# Save Model
mod_file = 'xgboost_smote.model'
pickle.dump(classifier_xgb, open(mod_file, 'wb'))

y_pred = classifier_xgb.predict(test_x)

from sklearn.metrics import classification_report

print(classification_report(test_y,y_pred))

y_proba = classifier_xgb.predict_proba(test_x)[:,1]

from sklearn.metrics import roc_curve, roc_auc_score
from sklearn.metrics import RocCurveDisplay

fpr, tpr, _ = roc_curve(test_y, y_proba)
roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)
auc = roc_auc_score(test_y, y_proba)

# Create Receiver Operating Characteristic curve
plt.figure(figsize = (10,10))
plt.plot(fpr,tpr,label="AUC= "+str(auc))
plt.ylabel('True Positive Rate (Sensitivity)')
plt.xlabel('False Positive Rate (Specificity)')
plt.legend(loc=4)
plt.show()

from sklearn.metrics import accuracy_score, confusion_matrix, f1_score,classification_report

accuracy = accuracy_score(test_y,y_pred)
print("Accuracy :",accuracy)

f1Score= f1_score(test_y,y_pred,average=None)
print("F1 Score :",f1Score)

conf_mat = confusion_matrix(test_y,y_pred)
print("Confusion Matrix :",conf_mat)

group_names = ['True Neg','False Pos','False Neg','True Pos']
group_counts = ['{0:0.0f}'.format(value) for value in
                conf_mat.flatten()]
group_percentages = ['{0:.2%}'.format(value) for value in
                    conf_mat.flatten()/np.sum(conf_mat)]
labels = [f'{v1}\n{v2}\n{v3}' for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(conf_mat, annot=labels, fmt='')

from sklearn.metrics import mean_squared_error,mean_absolute_error

mean_squared_error(test_y, y_pred)

mean_squared_error(test_y, y_pred, squared=False)

mean_absolute_error(test_y, y_pred)

"""### Train on Merged Dataset"""

from xgboost import XGBClassifier
classifier_xgb = XGBClassifier(learning_rate= 0.01,max_depth = 3,n_estimators = 1000)

classifier_xgb.fit(merged_x,merged_y)

# Save Model
mod_file = 'xgboost_merged.model'
pickle.dump(classifier_xgb, open(mod_file, 'wb'))

y_proba = classifier_xgb.predict_proba(test_x)[:,1]

from sklearn.metrics import roc_curve, roc_auc_score
from sklearn.metrics import RocCurveDisplay

fpr, tpr, _ = roc_curve(test_y, y_proba)
roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)
auc = roc_auc_score(test_y, y_proba)

# Create Receiver Operating Characteristic curve
plt.figure(figsize = (5,5))
plt.plot(fpr,tpr,label="AUC= "+str(auc))
plt.ylabel('True Positive Rate (Sensitivity)')
plt.xlabel('False Positive Rate (Specificity)')
plt.legend(loc=4)
plt.show()

"""After using an additional dataset, the ROC curve shows a much result as curve starts off much steeper and close to the top right. There are much less step-like patterns which means the model is able to generalise better and distinguish between true positive predictions and false positive predictions. However, this can be further improved by tuning various parameters, such as, learning rate and max depth."""

from sklearn.metrics import classification_report

y_pred = classifier_xgb.predict(test_x)
print(classification_report(test_y,y_pred))

from sklearn.metrics import accuracy_score, confusion_matrix, f1_score,classification_report

accuracy = accuracy_score(test_y,y_pred)
print("Accuracy :",accuracy)

f1Score= f1_score(test_y,y_pred,average=None)
print("F1 Score :",f1Score)

conf_mat = confusion_matrix(test_y,y_pred)
print("Confusion Matrix :",conf_mat)

from sklearn.metrics import mean_squared_error,mean_absolute_error
mean_absolute_error(test_y, y_pred)

"""## Hyperparameter tuning of XGBoost"""

import xgboost as xgb
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint

# define the parameter grid
param_dist = {'max_depth': randint(1, 10),
              'learning_rate': [0.01, 0.03, 0.05, 0.1],
              'min_child_weight': randint(1, 10)}

# instantiate an XGBoost classifier
xgb_clf = xgb.XGBClassifier()

# instantiate a RandomizedSearchCV object
rs = RandomizedSearchCV(xgb_clf, 
                        param_distributions=param_dist, 
                        n_iter=10, 
                        cv=10, 
                        random_state=42,
                        n_jobs=-1, 
                        verbose=2)

# fit the RandomizedSearchCV object to the data
rs.fit(merged_x, merged_y)

# print the results of each iteration
for i, params in enumerate(rs.cv_results_['params']):
    print("Iteration:", i)
    print("Params:", params)
    print("Mean Test Score:", rs.cv_results_['mean_test_score'][i])
    print("Rank:", rs.cv_results_['rank_test_score'][i])
    print()

"""Iteration: 4

Params: {'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 8}

Mean Test Score: 0.902122096881221

"""

# Define random search
random_search = RandomizedSearchCV(estimator=xgb_clf, 
                           param_distributions=param_dist, 
                           n_iter=20,
                           scoring='f1', 
                           refit='recall', 
                           n_jobs=-1, 
                           cv=10,
                           random_state=42, 
                           verbose=2)# Fit grid search
random_result = random_search.fit(merged_x, merged_y)# Print grid search summary
random_result# Print the best score and the corresponding hyperparameters
print(f'The best score is {random_result.best_score_:.4f}')
# print('The best score standard deviation is', round(random_result.cv_results_['std_test_recall'][random_result.best_index_], 4))
print(f'The best hyperparameters are {random_result.best_params_}')

"""## Hyperparameter tuning using Ray Tune"""

!pip install -U ray
from ray import tune

import xgboost as xgb

def Tune(config):
     # Build input matrices for XGBoost
     train_set = xgb.DMatrix(merged_x, label=merged_y)
     test_set = xgb.DMatrix(test_x, label=test_y)
     # Train the classifier
     results = {}
     xgb.train(
         config,
         train_set,
         evals=[(test_set, "eval")],
         evals_result=results,
         verbose_eval=False)
     # Return prediction accuracy
     accuracy = 1. - results["eval"]["error"][-1]
     tune.report(mean_accuracy=accuracy, done=True)


if __name__ == "__main__":
     config = {
         "objective": "binary:logistic",
         "eval_metric": ["logloss", "error"],
         "max_depth": tune.randint(1, 9),
         "min_child_weight": tune.choice([1, 2, 3]),
         "learning_rate": tune.choice([0.01, 0.001, 0.001]),
         "subsample": tune.uniform(0.5, 1.0),
         "eta": tune.loguniform(1e-4, 1e-1)
     }
     analysis = tune.run(
         Tune,
         resources_per_trial={"cpu": 1},
         config=config,
         num_samples=10)

"""1.   0.01 	= learning_rate
2.   7	= max_depth
3.   2	= min_child_weight
4.   0.56337 = Subsample 

0.823129	= Accuracy

## Evaluation using Tuned XGBoost Model
"""

# Shuffle dataset
merged_x, merged_y = shuffle(merged_x, merged_y, random_state=42)

print("Best Parameters: learning_rate= 0.01,max_depth = 7, min_child_weight= 2, n_estimators = 750" )

def train_and_plot(train_x, train_y, test_x, test_y, model_name):
  classifier_xgb = XGBClassifier(learning_rate= 0.01,max_depth = 7, min_child_weight= 2, n_estimators = 750)

  classifier_xgb.fit(train_x,train_y)

  # Save Model
  mod_file = model_name
  pickle.dump(classifier_xgb, open(mod_file, 'wb'))

  y_pred = classifier_xgb.predict(test_x)
  y_proba = classifier_xgb.predict_proba(test_x)[:,1]

  print(classification_report(test_y,y_pred))


  fpr, tpr, _ = roc_curve(test_y, y_proba)
  roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)
  auc = roc_auc_score(test_y, y_proba)

  # Create Receiver Operating Characteristic curve
  plt.figure(figsize = (5,5))
  plt.plot(fpr,tpr,label="AUC= "+str(auc))
  plt.ylabel('True Positive Rate (Sensitivity)')
  plt.xlabel('False Positive Rate (Specificity)')
  plt.legend(loc=4)
  plt.show()

  accuracy = accuracy_score(test_y,y_pred)
  print("Accuracy :",accuracy)

  f1Score= f1_score(test_y,y_pred,average=None)
  print("F1 Score :",f1Score)

  conf_mat = confusion_matrix(test_y,y_pred)
  print("Confusion Matrix :",conf_mat)


  group_names = ['True Neg','False Pos','False Neg','True Pos']
  group_counts = ['{0:0.0f}'.format(value) for value in
                  conf_mat.flatten()]
  group_percentages = ['{0:.2%}'.format(value) for value in
                      conf_mat.flatten()/np.sum(conf_mat)]
  labels = [f'{v1}\n{v2}\n{v3}' for v1, v2, v3 in
            zip(group_names,group_counts,group_percentages)]
  labels = np.asarray(labels).reshape(2,2)
  sns.heatmap(conf_mat, annot=labels, fmt='')

  print("Mean-squared error: ",mean_squared_error(test_y, y_pred))
  print("Root mean-squared error: ",mean_squared_error(test_y, y_pred, squared=False))
  print("Mean absolute error: ",mean_absolute_error(test_y, y_pred))



train_and_plot(merged_x, merged_y, test_x, test_y, 'xgboost_tuned_merged.model')

# Params: {'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 8}
train_and_plot(merged_x, merged_y, test_x, test_y, 'xgboost_randomcv', 0.1, 8, 8)

train_and_plot(merged_x, merged_y, test_x, test_y, 'xgboost_randomcv2', 0.01, 8, 8)

loaded_model = pickle.load(open('xgboost_tuned_merged.model', 'rb'))

from sklearn import metrics
from scipy.interpolate import interp1d
import matplotlib.pyplot as plt

y_pred = loaded_model.predict(test_x)
y_proba = loaded_model.predict_proba(test_x)[:,1]



# Calculate ROC curve and AUC
fpr, tpr, thresholds = metrics.roc_curve(test_y, y_proba)
roc_auc = metrics.auc(fpr, tpr)

# Create interpolation function
interp_fpr = np.linspace(0, 1, 100)
interp_tpr = interp1d(fpr, tpr)(interp_fpr)

# # Plot smoothed ROC curve
# plt.plot(interp_fpr, interp_tpr, label='Smoothed ROC curve (AUC = %0.2f)' % roc_auc)
# plt.plot(fpr, tpr, label='ROC curve (AUC = %0.2f)' % roc_auc, linestyle='--')
# plt.xlabel('False Positive Rate')
# plt.ylabel('True Positive Rate')
# plt.legend()
# plt.show()

# # Create Receiver Operating Characteristic curve
plt.plot(interp_fpr, interp_tpr, label='Smoothed ROC curve (AUC = %0.2f)' % roc_auc)
plt.plot(fpr, tpr, label='ROC curve (AUC = %0.2f)' % roc_auc, linestyle='--')
plt.ylabel('True Positive Rate (Sensitivity)')
plt.xlabel('False Positive Rate (Specificity)')
plt.legend(loc=4)
plt.show()

stats = stats.zscore(train_x_smote)

"""# Miscellaneous"""

numeric_cols = data.select_dtypes(include=['int64', 'float64']).columns.tolist()
categorical_cols = data.select_dtypes(include=['object']).columns.tolist()


data[numeric_cols].head()

data[categorical_cols].head()

# # Standardisation
# import numpy as np
# from sklearn.preprocessing import StandardScaler
# scaler = StandardScaler()
# scaler.fit(data)

# # standardise the data
# numeric_cols= scaler.transform(data)
# numeric_cols.hist()
# plot.show()
import matplotlib.pyplot as plt
plt.plot(data['MonthlyIncome'], data['Attrition'])
plt.xlabel('Monthly Income')
plt.show()
# plt.scatter(data['Attrition'] ,data['MonthlyIncome'], alpha=0.5)
# plt.show()

plt.hist('Age', bins=35)
plt.show()

import seaborn as sns
sns.countplot(data['Gender'])
# female_df = data[data['Gender'] == 'Female']
# # male_df = data[data['Gender'] == 'Male']
# # plt.pie(data['Gender'])
plt.show()
data['Gender'].value_counts()

# Reassign target
data.Attrition.replace(to_replace = dict(Yes = 1, No = 0), inplace = True)
# Drop useless feat
data = data.drop(columns=['StandardHours', 
                          'EmployeeCount', 
                          'Over18',
                        ])

data.dtypes

attrition = data[(data['Attrition'] != 0)]
no_attrition = data[(data['Attrition'] == 0)]


no_attrition.value_counts()

attrition.value_counts()

my_labels =["Attriton","No Attrition"]
plt.pie(data['Attrition'].value_counts(), labels=my_labels,autopct='%1.1f%%')
plt.title('Distribution of Attrition')

gender_attrition = attrition['Gender'].value_counts().values.tolist()
gender_labels  = attrition['Gender'].value_counts().keys().tolist()
plt.pie(gender_attrition, labels=gender_labels,autopct='%1.1f%%')
plt.title('Distribution of Attrition between Genders')

male_attrition = attrition['Gender'] == 'Male'
male_attrition.value_counts()

tmp3 = pd.DataFrame(pd.crosstab(data['Age'],data['Attrition']), )
# attrition = data[(data['Attrition'] != 0)]
# no_attrition = data[(data['Attrition'] == 0)]
tmp3['Attrition %'] = tmp3[1] / (tmp3[1] + tmp3[0]) * 100 
# ages_attrition = pd.DataFrame(pd.crosstab(data['Age'],[data['Attrition'] ==0]))

# tmp3 = tmp3.sort_values(1, ascending = False)
tmp3.head()

# width of the bar
barWidth = 0.5
fig = plt.subplots(figsize =(12, 8))

# set x and y for yes attrition and age bars
yes_attrition_x = attrition['Age'].value_counts().keys().tolist()
yes_attrition_y = attrition['Age'].value_counts().values.tolist()

# set x and y for no attrition and age bars
no_attrition_x = no_attrition['Age'].value_counts().keys().tolist()
no_attrition_y = no_attrition['Age'].value_counts().values.tolist()



# make the plot
plt.bar(no_attrition_x, no_attrition_y, width = barWidth,
        edgecolor ='grey', label ='Negative attrition with age')
plt.bar(yes_attrition_x, yes_attrition_y, width = barWidth,
        edgecolor ='grey', label ='Positive attrition with age')


# Adding Xticks
plt.xlabel('Age', fontweight ='bold', fontsize = 15)
plt.ylabel('Attrition', fontweight ='bold', fontsize = 15)

plt.legend()
plt.show()

rate_att = attrition['MonthlyIncome'].value_counts().keys().tolist()

rate_noatt = no_attrition['MonthlyIncome'].value_counts().keys().tolist()

rate_att = attrition['MonthlyIncome']
rate_noatt = no_attrition['MonthlyIncome']
yes_attrition_y = attrition['MonthlyIncome'].value_counts().values.tolist()
no_attrition_y = no_attrition['MonthlyIncome'].value_counts().values.tolist()

# Adding Xticks
plt.xlabel('Monthly Income', fontsize = 15)
plt.ylabel('Attrition', fontsize = 15)


rate_noatt.hist()
rate_att.hist()

data['Attrition'] = data['Attrition'].factorize(['No','Yes'])[0]
data.head()

attrition = data[(data['Attrition'] != 0)]
no_attrition = data[(data['Attrition'] == 0)]

plt.pie(data['Attrition'].value_counts(), labels = ['No attrition', 'Yes attrition'] )


plt.show()

plt.figure(figsize=(30, 30))
sns.heatmap(data.corr(), annot=True, cmap="RdYlGn", annot_kws={"size":14})

numeric_cols = data.select_dtypes(include=['int64', 'float64']).columns.tolist()
data[numeric_cols].head()

tmp1 = data[(data['Attrition'] != 0)]
tmp2 = data[(data['Attrition'] == 0)]

x1=tmp1['YearsSinceLastPromotion'].value_counts().keys().tolist()
y1=tmp1['YearsSinceLastPromotion'].value_counts().values.tolist()

x2=tmp2['YearsSinceLastPromotion'].value_counts().keys().tolist()
y2=tmp2['YearsSinceLastPromotion'].value_counts().values.tolist()
tmp3 = pd.DataFrame(pd.crosstab(data['YearsSinceLastPromotion'],data['Attrition']), )
tmp3['Attr%'] = tmp3[1] / (tmp3[1] + tmp3[0]) * 100
    # trace1 = go.Bar(
    #     x=tmp1[var_select].value_counts().keys().tolist(),
    #     y=tmp1[var_select].value_counts().values.tolist(),
    #     name='Yes_Attrition',opacity = 0.8, marker=dict(
    #     line=dict(color='#000000',width=1)))

    
    # trace2 = go.Bar(
    #     x=tmp2[var_select].value_counts().keys().tolist(),
    #     y=tmp2[var_select].value_counts().values.tolist(),
    #     name='No_Attrition', opacity = 0.8, marker=dict(
    #     line=dict(color='#000000',width=1)))
    
   

    # layout = dict(title =  str(var_select),
    #           xaxis=dict(), 
    #           yaxis=dict(title= 'Count'), 
    #           yaxis2=dict(range= [-0, 75], 
    #                       overlaying= 'y', 
    #                       anchor= 'x', 
    #                       side= 'right',
    #                       zeroline=False,
    #                       showgrid= False, 
    #                       title= '% Attrition'
    #                      ))

    # fig = go.Figure(data=[trace1, trace2], layout=layout)
    # py.iplot(fig)
plt.figure(figsize=(20,10))

fig, ax = plt.subplots()
ax.bar(x2, y2, label='No Attrition')
ax.bar(x1,y1,label='Attrition')

plt.xlabel('YearsSinceLastPromotion')
plt.ylabel('No. of Employees')



ax.legend()
plt.show

data[numeric_cols].head()

data.describe()

data_cmp = data[['Attrition', 'Age','DistanceFromHome', 'TotalWorkingYears','JobSatisfaction', 'Gender']].copy()

data_cmp.describe()

data['OverTime'] = data['OverTime'].factorize(['No','Yes'])[0]
data_cmp2= data[['Attrition', 'OverTime']].copy()
data_cmp2.head()



tmp1 = data[(data['Attrition'] != 0)]
tmp2 = data[(data['Attrition'] == 0)]

x1=tmp1['OverTime'].value_counts().keys().tolist()
y1=tmp1['OverTime'].value_counts().values.tolist()

x2=tmp2['OverTime'].value_counts().keys().tolist()
y2=tmp2['OverTime'].value_counts().values.tolist()
tmp3 = pd.DataFrame(pd.crosstab(data['OverTime'],data['Attrition']), )
tmp3['Attr%'] = tmp3[1] / (tmp3[1] + tmp3[0]) * 100

plt.figure(figsize=(20,10))

fig, ax = plt.subplots()
ax.bar(x2, y2, label='No Attrition')
ax.bar(x1,y1,label='Attrition')

plt.xlabel('OverTime')
plt.ylabel('No. of Employees')



ax.legend()
plt.show

data.isnull().values.any()

sns.boxplot(data=data, x="JobRole", y="MonthlyIncome")

sns.catplot(data=data, x="JobRole", hue="Attrition", kind="count", height=7, aspect=2, legend=False)
plt.legend(loc='upper right', title='Attrition')
plt.tight_layout()
plt.show()

# Scatter plot
fig, ax = plt.subplots(figsize = (18,10))
ax.scatter(data['YearsAtCompany'], data['MonthlyIncome'])

# x-axis label
ax.set_xlabel('Years at Company')
ax.set_ylabel('Monthly Income')

# y-axis label

plt.show()

sns.boxplot(x=data['JobSatisfaction'])

# Scatter plot
fig, ax = plt.subplots(figsize = (18,10))
ax.scatter(data['TotalWorkingYears'], data['MonthlyIncome'])

# x-axis label


# y-axis label

plt.show()



# Scatter plot
fig, ax = plt.subplots(figsize = (18,10))
ax.scatter(data['DistanceFromHome'], data['MonthlyIncome'])

# x-axis label


# y-axis label

plt.show()